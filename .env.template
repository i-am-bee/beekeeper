# LLM Provider (ibm_rits/ollama/openai)
LLM_BACKEND="ibm_rits"

## IBM RITS
### Llama 3.1 405b
IBM_RITS_URL_SUPERVISOR="https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3-1-405b-instruct-fp8/v1"
IBM_RITS_MODEL_SUPERVISOR="meta-llama/llama-3-1-405b-instruct-fp8"

## DeepSeek
# IBM_RITS_URL_SUPERVISOR="https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/deepseek-v3/v1"
# IBM_RITS_MODEL_SUPERVISOR="deepseek-ai/DeepSeek-V3"

# ### Granite 3.2 8b
# IBM_RITS_URL_SUPERVISOR="https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/granite-3-2-8b-instruct"
# IBM_RITS_MODEL_SUPERVISOR="ibm-granite/granite-3.2-8b-instruct"

# ### Llama 3.3 70b
# IBM_RITS_URL_SUPERVISOR="https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3-3-70b-instruct/v1"
# IBM_RITS_MODEL_SUPERVISOR="meta-llama/llama-3-3-70b-instruct"


IBM_RITS_URL_OPERATOR="https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3-3-70b-instruct/v1"
IBM_RITS_MODEL_OPERATOR="meta-llama/llama-3-3-70b-instruct"
IBM_RITS_API_KEY="<YOUR_RITS_API_KEY_HERE>"

## Ollama
OLLAMA_HOST="http://0.0.0.0:11434"
OLLAMA_MODEL_SUPERVISOR="deepseek-r1:8b"
OLLAMA_MODEL_OPERATOR="deepseek-r1:8b"

## OpenAI
OPENAI_API_KEY="<YOUR_OPEN_AI_API_KEY_HERE>"
OPENAI_MODEL_SUPERVISOR="gpt-4o"
OPENAI_MODEL_OPERATOR="gpt-4o"

# Framework related
BEE_FRAMEWORK_LOG_PRETTY=false
BEE_FRAMEWORK_LOG_LEVEL="debug"
BEE_FRAMEWORK_LOG_SINGLE_LINE="false"
