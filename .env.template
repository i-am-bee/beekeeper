# Tools
SEARCH_TOOL="tavily" # tavily/duckduckgo
TAVILY_API_KEY="<YOUR_TAVILY_API_KEY_HERE>"

# LLM Provider (openai/ollama/watsonx)
LLM_BACKEND="openai"           # Fallback backend for both agents. If both agentâ€‘specific variables below are set, this fallback is optional.
# LLM_BACKEND_SUPERVISOR="openai" # Backend for the supervisor agent
# LLM_BACKEND_OPERATOR="ollama"   # Backend for the operator agent

## OpenAI
OPENAI_API_KEY="<YOUR_OPEN_AI_API_KEY_HERE>"
OPENAI_MODEL_SUPERVISOR="gpt-4o-mini"
OPENAI_MODEL_OPERATOR="gpt-4o-mini"

## Ollama
OLLAMA_BASE_URL="http://0.0.0.0:11434/api"
OLLAMA_MODEL_SUPERVISOR="deepseek-r1:8b"
OLLAMA_MODEL_OPERATOR="deepseek-r1:8b"

## Watson X
WATSONX_API_KEY="<YOUR_WATSONX_API_KEY_HERE>"
WATSONX_BASE_URL="<YOUR_WATSONX_BASE_URL>"
WATSONX_PROJECT_ID="<YOUR_PROJECT_ID>"
WATSONX_CHAT_MODEL_SUPERVISOR="ibm/granite-3-3-8b-instruct"
WATSONX_CHAT_MODEL_OPERATOR="ibm/granite-3-3-8b-instruct"

# Framework related
BEE_FRAMEWORK_LOG_PRETTY=false
BEE_FRAMEWORK_LOG_LEVEL="debug"
BEE_FRAMEWORK_LOG_SINGLE_LINE="false"

# Development only
DEV_SUPERVISOR_WORKFLOW_ENABLED=true
DEV_SUPERVISOR_WORKFLOW_DISABLE_EXAMPLES=false